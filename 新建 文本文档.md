|                                                              |                            |                                                              |      |
| ------------------------------------------------------------ | -------------------------- | ------------------------------------------------------------ | ---- |
| 操作系统ISO全量构建方案                                      |                            |                                                              |      |
| 操作系统ISO全量构建方案                                      |                            |                                                              |      |
| **文档版本**                                                 | 01                         |                                                              |      |
| **发布日期**                                                 | 2023-01-04                 |                                                              |      |
| ![img](file:///C:\Users\liuyufei\AppData\Local\Temp\ksohtml7592\wps64.jpg) |                            |                                                              |      |
|                                                              | ***\*华为技术有限公司\**** | ![img](file:///C:\Users\liuyufei\AppData\Local\Temp\ksohtml7592\wps65.jpg) |      |



 

***\*版权所有 © 华为技术有限公司2023。 保留一切权利。\****非经本公司书面许可，任何单位和个人不得擅自摘抄、复制本文档内容的部分或全部，并不得以任何形式传播。 ***\*商标声明\****![img](file:///C:\Users\liuyufei\AppData\Local\Temp\ksohtml7592\wps66.jpg) 和其他华为商标均为华为技术有限公司的商标。本文档提及的其他所有商标或注册商标，由各自的所有人拥有。 ***\*注意\****您购买的产品、服务或特性等应受华为公司商业合同和条款的约束，本文档中描述的全部或部分产品、服务或特性可能不在您的购买或使用范围之内。除非合同另有约定，华为公司对本文档内容不做任何明示或暗示的声明或保证。由于产品版本升级或其他原因，本文档内容会不定期进行更新。除非另有约定，本文档仅作为使用指导，本文档中的所有陈述、信息和建议不构成任何明示或暗示的担保。

 

 

 

 

 

 

 

 

 

| 华为技术有限公司 |                                                     |
| ---------------- | --------------------------------------------------- |
| 地址：           | 深圳市龙岗区坂田华为总部办公楼   邮编：518129       |
| 网址：           | https://www.huawei.com                              |
| 客户服务邮箱：   | href="mailto:support@huawei.com" support@huawei.com |
| 客户服务电话：   | 4008302118                                          |

 

 

 



***\*目  录\****

[1 简介	](#_Toc256000000)

[1.1 目的	](#_Toc256000001)

[1.2 适用范围	](#_Toc256000002)

[2 准备工作	](#_Toc256000003)

[2.1 资源要求	](#_Toc256000004)

[3 部署	](#_Toc256000005)

[3.1 OBS环境搭建	](#_Toc256000006)

[3.1.1 OBS部署说明	](#_Toc256000007)

[3.1.2 方案一：物理机搭建	](#_Toc256000008)

[3.1.3 方案二：虚拟机搭建	](#_Toc256000009)

[3.1.3.1 前期准备	](#_Toc256000010)

[3.1.3.2 虚拟机相关软件安装	](#_Toc256000011)

[3.1.3.3 桥接模式创建	](#_Toc256000012)

[3.1.3.4 OBS server搭建	](#_Toc256000013)

[3.1.3.4.1 准备OBS server xml配置文件（X86）	](#_Toc256000014)

[3.1.3.4.2 启动OBS server	](#_Toc256000015)

[3.1.3.5 OBS worker搭建	](#_Toc256000016)

[3.1.3.5.1 准备OBS worker xml配置文件（ARM）	](#_Toc256000017)

[3.1.3.5.2 启动OBS worker	](#_Toc256000018)

[3.1.4 推荐方案	](#_Toc256000019)

[3.1.5 obs server配置	](#_Toc256000020)

[3.1.5.1 obs frontend节点环境初始化：	](#_Toc256000021)

[3.1.5.2 obs source节点环境初始化	](#_Toc256000022)

[3.1.5.3 obs backend节点环境初始化	](#_Toc256000023)

[3.1.5.4 obs home-backend节点环境初始化	](#_Toc256000024)

[3.1.6 obs worker配置	](#_Toc256000025)

[3.1.7 环境验证	](#_Toc256000026)

[3.1.8 常见问题解决	](#_Toc256000027)

[3.2 配置签名	](#_Toc256000028)

[3.2.1 前置说明	](#_Toc256000029)

[3.2.2 详细操作	](#_Toc256000030)

[3.2.2.1 生成公私钥	](#_Toc256000031)

[3.2.2.2 配置OBS签名	](#_Toc256000032)

[3.2.2.3 签名激活	](#_Toc256000033)

[3.2.2.4 导出公钥	](#_Toc256000034)

[4 使用	](#_Toc256000035)

[4.1 OBS工程搭建	](#_Toc256000036)

[4.1.1 源码准备	](#_Toc256000037)

[4.1.1.1 基于openEuler repo源码准备	](#_Toc256000038)

[4.1.1.2 基于用户自己搭建的gitlab代码托管平台构建	](#_Toc256000039)

[4.1.2 创建工程	](#_Toc256000040)

[4.1.3 导入jenkins任务	](#_Toc256000041)

[4.1.4 工程配置修改（for换标）	](#_Toc256000042)

[4.1.5 创建Extras工程	](#_Toc256000043)

[4.1.6 OBS常用操作介绍	](#_Toc256000044)

[4.2 二次发行构建流程	](#_Toc256000045)

[4.2.1 换标构建流程图	](#_Toc256000046)

[4.2.2 换标方案说明	](#_Toc256000047)

[4.3 编译	](#_Toc256000048)

[4.4 制作iso	](#_Toc256000049)

[4.4.1 准备环境	](#_Toc256000050)

[4.4.2 制作iso	](#_Toc256000051)

[4.4.3 参数说明	](#_Toc256000052)

[4.5 OBS构建FAQ	](#_Toc256000053)

[4.5.1 root构建	](#_Toc256000054)

[4.5.2 Maven源配置	](#_Toc256000055)

[4.5.3 obsworker DNS配置	](#_Toc256000056)

[4.5.4 rpmbuild命令行参数修改	](#_Toc256000057)

[4.5.5 obs构建环境注入环境变量	](#_Toc256000058)

[4.5.6 obs某种架构无法构建：	](#_Toc256000059)

[4.5.7 编译失败提示“rerun configure with different flags”或者“recompile with -fPIC”	](#_Toc256000060)

[4.5.8 Nodejs下载失败：	](#_Toc256000061)

[4.5.9 测试用例失败	](#_Toc256000062)

[4.5.10 kernel编译失败	](#_Toc256000063)

[4.5.11 flink构建失败	](#_Toc256000064)

[4.6 OBS搭建FAQ	](#_Toc256000065)

[4.6.1 frontend.sh、source.sh、backend.sh执行报错，提示内核版本不支持	](#_Toc256000066)

[4.6.2 frontend.sh中rake命令行执行报错:	](#_Toc256000067)

[4.6.3 frontend节点apache2.service因ssl证书不存在启动失败:	](#_Toc256000068)

[4.6.4 source节点source_server.sh脚本执行文件拷贝出错	](#_Toc256000069)

[4.6.5 backend 节点apache2服务启动失败，obs.conf下载失败导致	](#_Toc256000070)

[4.6.6 http://obsserver web访问失败	](#_Toc256000071)

[4.6.7 obs frontend节点 sphinx 服务启动失败	](#_Toc256000072)

[4.6.8 创建工程失败	](#_Toc256000073)

[4.6.9 osc命令报错	](#_Toc256000074)

[4.6.10 执行get_source.sh有如下报错：	](#_Toc256000075)

[4.6.11 backend如下报错：	](#_Toc256000076)

[4.6.12 软件包broken	](#_Toc256000077)

[4.6.13 整个工程的大量包都在scheduled状态且一直没有任何在building的包	](#_Toc256000078)

[4.6.14 如果网页上显示整个工程的大量包都在unresolvable状态	](#_Toc256000079)

[4.6.15 软件包failed，需要登录构建环境定位	](#_Toc256000080)

[4.6.16 obs worker x86镜像启动失败	](#_Toc256000081)

[4.6.17 obssource 节点 obsservice.service服务启动失败	](#_Toc256000082)



**
**

# **1** ***\*简介\****

[1.1  目的](#_ZH-CN_TOPIC_0000001423827940)

[1.2  适用范围](#_ZH-CN_TOPIC_0000001474144321)

## 1.1 目的

本文档用于指导OSV厂商基于OpenEuler构建自己的linux操作系统。

## 1.1 适用范围

obs构建环境是虚拟机（虚拟机镜像由openEuler提供）。 本文档基于x86_64架构编写，aarch64架构实际操作过程中略有差异。



# **2** ***\*准备工作\****

[2.1  资源要求](#_ZH-CN_TOPIC_0000001423668116)

## 1.1 资源要求

最简模式：

| 用途       | 架构   | 规格   | 磁盘大小 | 数量 |
| ---------- | ------ | ------ | -------- | ---- |
| OBS Server | X86_64 | 32U64G | 1T       | 1    |
| OBS Worker | X86_64 | 32U64G | 200G     | 30   |

 

在编译任务不繁重的情况下，1台server就可以满足需求。

集群模式：

| 用途       | 架构   | 规格   | 磁盘大小 | 数量 |
| ---------- | ------ | ------ | -------- | ---- |
| OBS Server | X86_64 | 32U64G | 1T       | 4    |
| OBS Worker | X86_64 | 32U64G | 200G     | 30   |

 

在编译任务繁重的情况下，server的各个子服务负载大，集群模式可以很好的将负载均摊到各个server中。

机器规格非固定，可根据实际情况提供不同规格的机器，规格越大，性能越好。32U64G是个较优的配置。因为编译时涉及大量的IO操作，worker的磁盘最好使用高性能的SSD盘。obs server数据盘大小至少500G，obs worker数量1台即可编译，worker数量越多，编译越快。如果需要编译aarch64的版本，则把worker的架构换成aarch64即可。



# **3** ***\*部署\****

[3.1  OBS环境搭建](#_ZH-CN_TOPIC_0000001473904345)

[3.2  配置签名](#_ZH-CN_TOPIC_0000001423827952)

## 1.1 OBS环境搭建

### 1.1.1 OBS部署说明

我们使用open build service提供的开源方案部署了 openEuler自己的包持续构建平台，并且参照open build service的[官方建议](https://gitee.com/link?target=https%3A%2F%2Fopenbuildservice.org%2Fhelp%2Fmanuals%2Fobs-admin-guide%2Fobs.cha.installation_and_configuration.html)，按照下面的方式部署了集群:

![img](file:///C:\Users\liuyufei\AppData\Local\Temp\ksohtml7592\wps67.jpg) 

这里面包含的组件有:

1. 前端(frontend): 部署了服务的前端组件，包括数据库，网站等。
2. 源代码端(source): 部署了服务的代码仓库组件。
3. 主后端(backend): 部署了一套完整的后端组件，负责除去home project外，其他项目的调度，构建，发布。
4. home项目后端(home-backend): 部署了一套完整的后端组件，负责所有home project的调度，构建，发布。
5. 很多x86 aarch64的worker，这些worker大部分只服务于主后端组件，少量服务于home项目后端。

假设我们四台机器均在一个互通的子网内，他们之间可通过子网IP访问，IP具体信息如下:

1. frontend: 172.16.1.81
2. source: 172.16.1.89
3. backend: 172.16.1.95
4. home-backend: 172.16.1.84

注意: 如果机器在不同的子网内，需要保证服务端口开放。

### 3.0.1 方案一：物理机搭建

**前期准备：**

物理机，obs-server.x86_64-oem.iso，CentOS-7-x86_64-DVD-1810.iso，obs服务启动脚本（https://gitee.com/openeuler/infrastructure.git）

**搭建步骤：**

1）  物理机上使用obs-server.x86_64-oem.iso和CentOS-7-x86_64-DVD-1810.iso安装系统

2）  每台机器执行相应的服务启动脚本启动服务

3）  生成用于rpm包签名的公私钥并配置签名服务

优点：物理机规格较大，性能较好

缺点：需要手动安装操作系统，无法批量启动机器

搭建耗时：2人天

### 3.0.2 方案二：虚拟机搭建

#### 1.1.1.1 前期准备

1. 可创建虚拟机的host机器
2. 咨询TH方获取obs server和worker的虚拟机镜像（说明：镜像现无永久有效的下载地址，需要找TH工作人员提供）

OBS server虚拟机用户密码：

用户名：root

密码：opensuse

OBS worker虚拟机用户密码：

用户名：root

密码：openeuler@1234

#### 3.0.2.1 虚拟机相关软件安装

安装QEMU组件：

yum install -y qemu

安装libvirt组件。

yum install -y libvirt virt-install

安装edk2：

Host机器为X86：

yum install -y edk2-ovmf

host机器为ARM64：

yum install -y edk2-aarch64

启动libvirtd服务。

systemctl start libvirtd

验证是否安装成功可参考：[https://docs.openeuler.org/zh/docs/22.03_LTS/docs/Virtualization/%E5%AE%89%E8%A3%85%E8%99%9A%E6%8B%9F%E5%8C%96%E7%BB%84%E4%BB%B6.html](https://docs.openeuler.org/zh/docs/22.03_LTS/docs/Virtualization/安装虚拟化组件.html)

创建一个数据盘：

qemu-img create -f qcow2 obsServerData.qcow2 200G

备注：创建数据盘根据自己实际情况在server和work的物理机上执行。

表3-1 

| 节点             | 数据盘大小推荐 |
| ---------------- | -------------- |
| obs frontend     | 500G           |
| obs source       | 1T             |
| obs backend      | 500G           |
| obs home-backend | 500G           |
| obs worker       | 300G           |

 

#### 3.0.2.2 桥接模式创建

桥接模式需要宿主机配置一个虚拟网卡，该虚拟网卡桥接到宿主机的一个真实物理网卡上。guest虚拟机安装的时候指定使用bridge的那个虚拟网卡即可。

例如，宿主机的IP地址是192.168.217.17，真实的物理网卡名称是ens33，那么，应该是这么配置的：

[root@slave1 ~]# cat /etc/sysconfig/network-scripts/ifcfg-ens33  
TYPE="Ethernet" 
BRIDGE="br0" 
BOOTPROTO="static" 
DEFROUTE="yes" 
IPV4_FAILURE_FATAL="no" 
NAME="ens33" 
UUID="d4876b9f-42d8-446c-b0ae-546e812bc954" 
DEVICE="ens33" 
ONBOOT="yes" 
[root@slave1 ~]# cat /etc/sysconfig/network-scripts/ifcfg-br0  
TYPE="Bridge" 
NAME="br0" 
BOOTPROTO="static" 
DEFROUTE="yes" 
DEVICE="br0" 
ONBOOT="yes" 
PREFIX="24" 
IPADDR=192.168.217.17 
NETMASK=255.255.255.0 
GATEWAY=192.168.217.2 
DNS1=8.8.8.8

注意：物理网卡尽量只增加红色一条，其他不要动。

配置好后，重启设备。

备注：红色部分需要根据用户自己的网络配置修改，另外由于OBS server需要4个虚拟机，并且worker也需要在一个机器上配置多个worker虚拟机实例，因此需要给OBS服务器预留多个IP地址用于虚拟机配置。

#### 3.0.2.3 OBS server搭建

注意：由于OBS server实际需要启动4个虚拟机，因此以下步骤需要重复4次。对应的系统镜像和磁盘镜像也需要复制4份。

##### 1.1.1.1.1 准备OBS server xml配置文件（X86）

文件命名为：obsServerVM.xml

<domain type='kvm'>   <name>obsServerVM</name>   <memory unit='GiB'>64</memory>   <currentMemory unit='GiB'>64</currentMemory>   <vcpu placement='static'>12</vcpu>   <iothreads>1</iothreads>   <os>     <type arch='x86_64' machine='pc-i440fx-4.0'>hvm</type>   </os>   <features>     <acpi/>   </features>   <cpu mode='host-passthrough' check='none'>     <topology sockets='2' cores='6' threads='1'/>   </cpu>   <clock offset='utc'/>   <on_poweroff>destroy</on_poweroff>   <on_reboot>restart</on_reboot>   <on_crash>restart</on_crash>   <devices>     <emulator>/usr/libexec/qemu-kvm</emulator>     <disk type='file' device='disk'>       <driver name='qemu' type='qcow2' iothread='1'/>       <source file='/obs/openEuler-image.qcow2'/>       <target dev='vda' bus='virtio'/>       <boot order='1'/>     </disk>     <disk type='file' device='disk'>       <driver name='qemu' type='qcow2' iothread='1'/>       <source file='/obs/obsServerData.qcow2'/>       <target dev='vda' bus='virtio'/>       <boot order='2'/>     </disk>     <controller type='scsi' index='0' model='virtio-scsi'>     </controller>     <controller type='virtio-serial' index='0'>     </controller>     <controller type='usb' index='0' model='ehci'>     </controller>     <controller type='sata' index='0'>     </controller>     <controller type='pci' index='0' model='pci-root'/>     <interface type='bridge'>       <source bridge='br0'/>       <model type='virtio'/>     </interface>     <serial type='pty'>       <target type='isa-serial' port='0'>         <model name='isa-serial'/>       </target>     </serial>     <console type='pty'>       <target type='serial' port='0'/>     </console>     <input type='tablet' bus='usb'>       <address type='usb' bus='0' port='1'/>     </input>     <input type='keyboard' bus='usb'>       <address type='usb' bus='0' port='2'/>     </input>     <input type='mouse' bus='ps2'/>     <input type='keyboard' bus='ps2'/>     <graphics type='vnc' port='-1' autoport='yes' listen='0.0.0.0'>       <listen type='address' address='0.0.0.0'/>     </graphics>     <video>       <model type='vga' vram='16384' heads='1' primary='yes'/>       <address type='pci' domain='0x0000' bus='0x00' slot='0x02' function='0x0'/>     </video>     <memballoon model='virtio'>     </memballoon>   </devices> </domain>

备注：

1.红色的是需要根据实际情况修改的参数。

2.黄色的不同的机器可能存在不一样的情况，可能存在使用virtio，rtl8319等。判断方法是虚拟机启动失败或者是进入到虚拟机之后没有网卡，则更换参数试试。

##### 3.0.2.3.1 启动OBS server

创建并启动虚拟机

virsh define obsServerVM.xml

virsh start obsServerVM

连接虚拟机：

virsh console osbServerVM

配置静态IP地址：

vi /etc/sysconfig/network-scripts/ifcfg-xxx

然后如下参数：

![img](file:///C:\Users\liuyufei\AppData\Local\Temp\ksohtml7592\wps68.jpg) 

注意：配置的IP地址一定要提前规划好，不能存在冲突，如果存在冲突，则会出现ip地址无法配置生效的现象。

然后重启虚拟机。

后续可以使用配置好的IP地址登录。

注意：退出虚拟机使用Ctrl+] 。

**到这里OBS server已经启动完毕，对于obs Server的配置见“obs server配置”章节。**

#### 3.0.2.4 OBS worker搭建

##### 1.1.1.1.1 准备OBS worker xml配置文件（ARM）

文件名：obsWorkerVM.xml

<domain type='kvm'>     <name>obsWorkerVM</name>     <memory unit='GiB'>16</memory>     <vcpu>8</vcpu>     <os>         <type arch='aarch64' machine='virt'>hvm</type>         <loader readonly='yes' type='pflash'>/usr/share/edk2/aarch64/QEMU_EFI-pflash.raw</loader>         <nvram>/var/lib/libvirt/qemu/nvram/openEulerVM.fd</nvram>     </os>     <features>         <acpi/>         <gic version='3'/>     </features>     <cpu mode='host-passthrough'>         <topology sockets='2' cores='2' threads='1'/>     </cpu>     <iothreads>1</iothreads>     <clock offset='utc'/>     <on_poweroff>destroy</on_poweroff>     <on_reboot>restart</on_reboot>     <on_crash>restart</on_crash>     <devices>         <emulator>/usr/libexec/qemu-kvm</emulator>         <disk type='file' device='disk'>             <driver name='qemu' type='qcow2' iothread="1"/>             <source file='/obs/obs-arm-worker.qcow2'/>             <target dev='vda' bus='virtio'/>             <boot order='1'/>         </disk>     <disk type='file' device='disk'>       <driver name='qemu' type='qcow2' iothread='1'/>       <source file='/obs/obsWorkerData.qcow2'/>       <target dev='vda' bus='virtio'/>       <boot order='2'/>     </disk>         <interface type='bridge'>             <source bridge='br0'/>             <model type='virtio'/>         </interface>         <console type='pty'/>         <video>            <model type='virtio'/>         </video>         <controller type='scsi' index='0' model='virtio-scsi'/>         <controller type='usb' model='ehci'/>         <input type='tablet' bus='usb'/>         <input type='keyboard' bus='usb'/>         <graphics type='vnc' listen='0.0.0.0' passwd='n8VfjbFK'/>     </devices>     <seclabel type='dynamic' model='dac' relabel='yes'/> </domain>

##### 3.0.2.4.1 启动OBS worker

创建并启动虚拟机

virsh define obsWorkerVM.xml

virsh start obsWorkerVM

连接虚拟机：

virsh console obsWorkerVM

注意：退出虚拟机使用Ctrl+] 。

**到这里OBS obsWorkerVM已经启动完毕，对于obs obsWorkerVM的配置见“obs worker配置”章节。**

对于一个机器上部署多个woker的情况：

1. 需要修改配置文件名字和xml内的Name。例如obsWorkVM1.xml，obsWorkVM2.xml，obsWorkVM3.xml，obsWorkVM4.xml。
2. 复制多份obs-arm-worker.qcow2和数据盘，然后启动。

### 3.0.3 推荐方案

虚拟机搭建方式，可直接咨询TH方获取到虚拟机镜像，镜像内已部署好obs组件，obs server服务可直接启动。 相较于物理机搭建方式中的一步步地从安装os系统、安装obs组件，再到启动obs服务的一系列操作，以TH镜像直接启动虚拟机搭建的方式会简单很多。

故， 建议使用虚拟机搭建集群模式的OBS服务，虚拟机规格如第一章节所述。SSD磁盘，不循环编译的情况下，30台worker，每个worker 10个实例编译时长大概8小时，10台worker编译时长大概12小时。

例如64U128G的物理机做worker，则建议部署4个woker。

### 3.0.4 obs server配置

**注意：如果使用的虚拟机方式搭建，则以下配置都是在虚拟机内执行，切勿在host机器上执行。**

#### 1.1.1.1 obs frontend节点环境初始化：

脚本下载链接：https://gitee.com/openeuler/infrastructure/tree/master/obs/tf/startup

在执行frontend.sh脚本前，需要检查ssl证书是否存在，脚本中检查代码如下：

![img](file:///C:\Users\liuyufei\AppData\Local\Temp\ksohtml7592\wps69.jpg) 

若不存在，参照如下方式生成，并放到/srv/obs/certs/目录下：

openssl req -new -x509 -days 3650 -nodes -out fullchain.pem -keyout privkey.pem

openssl req -new -x509 -days 3650 -nodes -out fullchain.pem -keyout privkey.pem -subj “/CN=换成真实域名，如build.openeuler.org”

安装说明 tf/startup/frontend.sh文件，提供了基本的执行脚本，用于拉起前端服务，拷贝到机器后，执行命令如下:

./frontend.sh 172.16.1.81 172.16.1.89 172.16.1.95 172.16.1.84

我们可以通过下面指令确认服务是否正常启动，重点关注frontend.sh中start的服务。

systemctl list-units | grep -E 'obs|memcached|mariadb|apache2'

the output would be like:

apache2.service                   loaded active running  The Apache Webserver 
mariadb.service                   loaded active running  MySQL server 
memcached.service                  loaded active running  memcached daemon 
obs-clockwork.service                loaded active running  Open Build Service Clockwork Daemon 
obs-delayedjob-queue-consistency_check.service   loaded active running  Open Build Service DelayedJob Queue: consistency_check 
obs-delayedjob-queue-default.service        loaded active running  Open Build Service DelayedJob Queue: default 
obs-delayedjob-queue-issuetracking.service     loaded active running  Open Build Service DelayedJob Queue: issuetracking 
obs-delayedjob-queue-mailers.service        loaded active running  Open Build Service DelayedJob Queue: mailers 
obs-delayedjob-queue-project_log_rotate.service   loaded active running  Open Build Service DelayedJob Queue: project_log_rotate 
obs-delayedjob-queue-quick@0.service        loaded active running  Open Build Service DelayedJob Queue Instance: quick 
obs-delayedjob-queue-quick@1.service        loaded active running  Open Build Service DelayedJob Queue Instance: quick 
obs-delayedjob-queue-quick@2.service        loaded active running  Open Build Service DelayedJob Queue Instance: quick 
obs-delayedjob-queue-releasetracking.service    loaded active running  Open Build Service DelayedJob Queue: releasetracking 
obs-delayedjob-queue-staging.service        loaded active running  Open Build Service DelayedJob Queue: staging 
obs-sphinx.service                 loaded active running  Open Build Service Sphinx Search Daemon 
obsstoragesetup.service               loaded active exited   OBS storage setup 
system-obs\x2ddelayedjob\x2dqueue\x2dquick.slice  loaded active active   system-obs\x2ddelayedjob\x2dqueue\x2dquick.slice 
obs-api-support.target               loaded active active   Open Build Service API Support Daemons

同时 hosts文件会添加集群内其他机器的host ip映射信息:

172.16.1.81 build.openeuler.org  
172.16.1.89 source.openeuler.org  
172.16.1.95 backend.openeuler.org  
172.16.1.84 home-backend.openeuler.org

#### 3.0.4.1 obs source节点环境初始化

脚本和配置下载链接：https://gitee.com/openeuler/infrastructure/tree/master/obs/tf/startup

执行source_server.sh前，完成如下准备工作：

1、将附件中BSConfig.pm配置文件存放至source节点/usr/lib/obs/server路径下（脚本中curl地址可能访问不到，将curl命令注释掉）：BSConfig.rar

2、根据自己环境网段情况，对BSConfig.pm文件进行如下适配（172.16为openEuler环境的）：

![img](file:///C:\Users\liuyufei\AppData\Local\Temp\ksohtml7592\wps70.jpg) 

安装说明 tf/startup/source_server.sh文件，提供了基本的执行脚本，用于拉起源代码服务，拷贝到机器后，执行命令如下:

./source_server.sh 172.16.1.81 172.16.1.89 172.16.1.95 172.16.1.84 /dev/vdb

/dev/vdb提前准备的磁盘，由于source机器会用来存储所有的代码，建议配置一个至少2T空间的SSD磁盘。

我们可以通过下面指令确认服务是否正常启动，重点关注source_server.sh中start的服务。

systemctl list-units | grep obs 
obsdeltastore.service                              loaded active running  OBS deltastore daemon obsservicedispatch.service                        loaded active running  OBS source service dispatcher obssrcserver.service                         loaded active running  OBS source repository server obsstoragesetup.service                    loaded active exited   OBS storage setup

同时 hosts文件会添加集群内其他机器的host ip映射信息:

172.16.1.81 build.openeuler.org  
172.16.1.89 source.openeuler.org  
172.16.1.95 backend.openeuler.org  
172.16.1.84 home-backend.openeuler.org

#### 3.0.4.2 obs backend节点环境初始化

脚本和配置下载链接：https://gitee.com/openeuler/infrastructure/tree/master/obs/tf/startup

执行backend.sh前，完成如下准备工作：

1、准备较大空间的空闲磁盘

2、脚本中配置文件不存在，需要从附件中获取，并添加到对应路径：config.rar

![img](file:///C:\Users\liuyufei\AppData\Local\Temp\ksohtml7592\wps71.jpg) 

3、修改BSConfig.pm中如下红框处为自己环境的网段：

![img](file:///C:\Users\liuyufei\AppData\Local\Temp\ksohtml7592\wps72.jpg) 

4、需要把source上的/srv/obs/configuration.xml考到backend同样的位置。

安装说明 tf/startup/backend.sh文件，提供了基本的执行脚本，用于拉起源代码服务，拷贝到机器后，执行命令如下:

./backend.sh 172.16.1.81 172.16.1.89 172.16.1.95 172.16.1.84 361466436 /dev/vdb

/dev/vdb提前准备的磁盘，由于backend机器会用来存储所有的构建包，建议配置一个至少4T空间的SAS磁盘。 361466436:配置的repoID，需要跟Source机器上的repoID保持一致，当在Source机器上执行脚本时，界面会显示Source机器的repoID。

我们可以通过下面指令确认服务是否正常启动，重点关注backend.sh中start的服务。

systemctl list-units | grep obs -e "obs|apache2"

the output would include:

apache2.service     loaded active running  The Apache Webserver 
obsdispatcher.service  loaded active   running     OBS job dispatcher daemon 
obsdodup.service     loaded active   running     OBS dodup, updates download on demand metadata 
obspublisher.service   loaded active   running     OBS repository publisher 
obsrepserver.service   loaded active   running     OBS repository server 
obsscheduler.service   loaded active   exited      OBS job scheduler 
obsservice.service    loaded active   running     OBS source service server 
obssignd.service     loaded active   running     LSB: start the gpg sign daemon 
obssigner.service    loaded active   running     OBS signer service 
obswarden.service    loaded active   running     OBS warden, monitors the workers

同时 hosts文件会添加集群内其他机器的host ip映射信息:

172.16.1.81 build.openeuler.org  
172.16.1.89 source.openeuler.org  
172.16.1.95 backend.openeuler.org  
172.16.1.84 home-backend.openeuler.org

#### 3.0.4.3 obs home-backend节点环境初始化

脚本和配置下载链接：https://gitee.com/openeuler/infrastructure/tree/master/obs/tf/startup

准备工作同backend节点初始化步骤，附件：home-config.rar

安装说明 tf/startup/home-backend.sh文件，提供了基本的执行脚本，用于拉起源代码服务，拷贝到机器后，执行命令如下:

./home-backend.sh 172.16.1.81 172.16.1.89 172.16.1.95 172.16.1.84 361466436 /dev/vdb

/dev/vdb提前准备的磁盘，由于backend机器会用来存储所有的构建包，建议配置一个至少2T空间的SSD磁盘。 361466436:配置的repoID，需要跟Source机器上的repoID保持一致，当在Source机器上执行脚本时，界面会显示Source机器的repoID。

我们可以通过下面指令确认服务是否正常启动，重点关注home-backend.sh中start的服务。

systemctl list-units | grep obs -e "obs|apache2"

the output would include:

apache2.service      loaded active running  The Apache Webserver 
obsdispatcher.service   loaded active   running     OBS job dispatcher daemon 
obsdodup.service      loaded active   running     OBS dodup, updates download on demand metadata 
obspublisher.service    loaded active   running     OBS repository publisher 
obsrepserver.service    loaded active   running     OBS repository server 
obsscheduler.service    loaded active   exited      OBS job scheduler 
obsservice.service     loaded active   running     OBS source service server 
obssignd.service      loaded active   running     LSB: start the gpg sign daemon 
obssigner.service     loaded active   running     OBS signer service 
obswarden.service     loaded active   running     OBS warden, monitors the workers

同时 hosts文件会添加集群内其他机器的host ip映射信息:

172.16.1.81 build.openeuler.org  
172.16.1.89 source.openeuler.org  
172.16.1.95 backend.openeuler.org  
172.16.1.84 home-backend.openeuler.org

### 3.0.5 obs worker配置

**注意：如果使用的虚拟机方式搭建，则以下配置都是在虚拟机内执行，切勿在host机器上执行。**

脚本和配置下载链接：https://gitee.com/openeuler/infrastructure/tree/master/obs/tf/startup

1. 要求 目前openEuler支持x86和aarch64 2种平台的构建，我们使用的worker机器对应的操作系统如下：
2. x86(centos 7.6)，对应的初始化脚本是worker.sh
3. aarch(euleros 2.x),对应的初始化脚本是worker_centos.sh
4. 安装说明 worker机器在高并发的情况下，对磁盘IO占用比较高，建议挂载SSD或者直接挂载内存作为worker的工作目录(/var/cache/obs/worker)，如果是磁盘，直接执行命令即可:

./worker.sh 172.16.1.81 172.16.1.89 172.16.1.95 172.16.1.84 /dev/vdb

如果是使用内存，如要提前准备好挂载的内存:

mkdir -p /var/cache/obs/worker && echo "tmpfs /var/cache/obs/worker tmpfs  nodev,nosuid,noexec,nodiratime,size=200G  0 0" >> /etc/fstab && reboot

然后再执行脚本:

./worker.sh 172.16.1.81 172.16.1.89 172.16.1.95 172.16.1.84

我们可以通过下面的指令确认需要的服务已经起来。

systemctl list-units | grep obs

the output would include:

obsworker.service       loaded active running  LSB: Open Build Service worker

obsworker服务的配置文件在: /etc/sysconfig/obs-server, 其中重点的参数包括:

1. OBS_SRC_SERVER: 指向source server。
2. OBS_REPO_SERVERS: 指向我们的后端服务，配置配置多个后端地址，以空格隔开，表明同时注册给多个后端。
3. OBS_WORKER_INSTANCES: worker的实例数。
4. OBS_WORKER_JOBS：每个worker的cpu数，系统计算根据当前机器的*核数/实例数*计算得来。
5. OBS_WORKER_DIRECTORY: worker的工作目录，默认指向/var/cache/obs/worker。

同时 hosts文件会添加集群内其他机器的host ip映射信息:

172.16.1.81 build.openeuler.org  
172.16.1.89 source.openeuler.org  
172.16.1.95 backend.openeuler.org  
172.16.1.84 home-backend.openeuler.org

### 3.0.6 环境验证

在浏览器中输入monitor，显示以下内容说明OBS环境部署成功：

![img](file:///C:\Users\liuyufei\AppData\Local\Temp\ksohtml7592\wps73.jpg) 

说明：图中deltastore非必要组件，可忽略。

或使用 osc api -X “/worker/_status”返回能看到对应的worker名字(与虚机的hostname相关)即部署成功。

附：搭建步骤及脚本可参考https://gitee.com/openeuler/infrastructure/tree/master/obs/docs

### 3.0.7 常见问题解决

前置：obs server、worker环境上系统和obs组件已安装完成。

启动obs服务：采取虚拟机镜像部署时，虚拟机启动时会自动启动obs相关服务，Obs服务启动后，在浏览器中输入 可成功链接，即表示服务启动成功。

**过程中常见问题与解决措施**：

问题1：obs-delayedjob-***服务启动失败。

失败原因：系统内存太小（如1G），导致服务启动过程内存申请失败。

解决措施：增加系统内存至16G以上。

问题2：启动过程中obsapisetup服务概率性启动失败。

失败原因：obsapisetup服务依赖于mysql服务，启动过程中obsapisetup服务启动时mysql还未启动完成。

解决措施：重启该服务临时恢复。或在obsapisetup服务配置文件中增加依赖After=mysql永久恢复。

## 3.1 配置签名

在 obs server环境上backend所在环境执行以下操作完成签名配置。

### 1.1.1 前置说明

如果签名服务存在问题，可以参照如下步骤解决：

Opensuse 15.1 默认镜像中的obs签名机制存在bug，报错信息如下图所示：

![img](file:///C:\Users\liuyufei\AppData\Local\Temp\ksohtml7592\wps74.jpg) 

解决方法：按https://github.com/openSUSE/obs-sign/pull/19/commits/bf3c981f791c612dbc6370f0b7af6c0bf780853c 补丁内容修改obs server环境上的/usr/sbin/signd脚本。

### 3.1.1 详细操作

#### 1.1.1.1 生成公私钥

按下述步骤操作，生成公私钥，其中红色字体部分即为公钥。

gpg --gen-key --pinentry-mode=loopback

\# 设置名称和邮件地址

Real name: My Build Service

Email address: obsrun@localhost

Comment:

You selected this USER-ID:

  "My Build Service <obsrun@localhost>"

  "My Build Service <obsrun@localhost>"

You need a Passphrase to protect your secret key.

\# （密码输入窗口）

gpg: checking the trustdb

gpg: 3 marginal(s) needed, 1 complete(s) needed, PGP trust model

gpg: depth: 0  valid:  2  signed:  0  trust: 0-, 0q, 0n, 0m, 0f, 2u

gpg: next trustdb check due at 2021-11-29

pub  1024R/DF205702 2016-11-30 [expires: 2021-11-29]

Key fingerprint = 7B54 7EB1 86AE 491E DCB2  E9C8 515E 5B50 DF20 5702

uid    [ultimate] My Build Service <obsrun@localhost>

sub  1024R/CEBFE72F 2016-11-30 [expires: 2021-11-29]

#### 3.1.1.1 配置OBS签名

1. 导出公钥：

mkdir -v /root/.phrases

\#在此目录下创建一个文件，命名为GPG密钥里的邮件地址，在此处为obsrun@localhost，文件的内容是密钥的密码。

vim /root/.phrases/obsrun@localhost  # 在这个文件中写上《生成公私钥》章节中设置的GPG密码

ln -s /root/.gnupg /

cp -r /root/.gnupg/* /srv/obs/gnupg/

gpg --armor --export DF205702 > /etc/obs-default-gpg.asc  # DF205702即为《生成公私钥》章节中生成的公钥

gpg --armor --export DF205702 > /srv/obs/obs-default-gpg.asc

1. 配置BSConfig.pm：

vim /usr/lib/obs/server/BSConfig.pm，按以下参数进行配置。

our $gpg_standard_key = "/etc/obs-default-gpg.asc";

\# No package signing server

our $sign = "/usr/bin/sign";

\# Extend sign call with project name as argument "--project $NAME"

\# 签名使能设置

our $sign_project = 0;

\# Global sign key

our $keyfile = "/srv/obs/obs-default-gpg.asc";

our $forceprojectkeys = 0;

1. 配置sign.conf：

vim /etc/sign.conf，按以下参数进行配置。

user: obsrun@localhost

allowuser: obsrun

allow: 127.0.0.1

phrases: /root/.phrases

#### 3.1.1.2 签名激活

systemctl restart obssignd obssigner

#### 3.1.1.3 导出公钥

/etc/obs-default-gpg.asc中的内容是公钥，需要用backend上的替换openEuler-repos源码中的公钥RPM-GPG-KEY-generic，此公钥用于验证rpm包的签名，在安装完openEuler-gpg-keys后会自动导入该公钥。

完成以上操作后重启机器。

如果有多台backend进行工程构建，需要用主backend的公钥覆盖其余backend的公钥。

附：签名配置可参考https://en.opensuse.org/openSUSE:Build_Service_Signer



# **4** ***\*使用\****

[4.1  OBS工程搭建](#_ZH-CN_TOPIC_0000001473904373)

[4.2  二次发行构建流程](#_ZH-CN_TOPIC_0000001473984881)

[4.3  编译](#_ZH-CN_TOPIC_0000001424144868)

[4.4  制作iso](#_ZH-CN_TOPIC_0000001423827968)

[4.5  OBS构建FAQ](#_ZH-CN_TOPIC_0000001474144317)

[4.6  OBS搭建FAQ](#_ZH-CN_TOPIC_0000001473784613)

## 1.1 OBS工程搭建

### 1.1.1 源码准备

#### 1.1.1.1 基于openEuler repo源码准备

注意：用户需要根据自己要构建的系统版本自行修改下载的ISO等路径。

iso下载路径：https://repo.openeuler.org/，根据实际需要下载对应版本iso，下面以openEuler-20.03-LTS-SP1为例：

下载iso、infrastructure和obs_meta，归档到obs source机器的/srv/work目录：

1、在https://repo.openeuler.org/openEuler-20.03-LTS-SP1/下载[openEuler-20.03-LTS-SP1-everything-x86_64-dvd.iso](https://repo.openeuler.org/openEuler-20.03-LTS-SP1/ISO/x86_64/openEuler-20.03-LTS-SP1-everything-x86_64-dvd.iso)、[openEuler-20.03-LTS-SP1-source-dvd.iso](https://repo.openeuler.org/openEuler-20.03-LTS-SP1/ISO/source/openEuler-20.03-LTS-SP1-source-dvd.iso)和https://repo.openeuler.org/openEuler-20.03-LTS-SP1/update/下的源码，同时用update的src.rpm替换iso中同名rpm包的源码。

2、下载https://gitee.com/openeuler/infrastructure.git和 https://gitee.com/src-openeuler/obs_meta.git

3、获取附件中工程创建脚本，拷贝至/srv/work目录，且根据实际版本适配脚本中的参数scripts.zip：

![img](file:///C:\Users\liuyufei\AppData\Local\Temp\ksohtml7592\wps75.jpg) 

4、 归档源码至source服务器对应路径下：

source机器/srv/work目录下，执行get_source.sh脚本获取源码。该脚本会将源码归档在/srv/work/sources目录下。

#### 4.0.0.1 基于用户自己搭建的gitlab代码托管平台构建

如果用户有自己的gitlab平台提供源码，则只需要上一个章节中的script.rar脚本即可，并按照上一个章节的步骤3放到对应的目录下。

### 4.0.1 创建工程

1、创建Mainline及BaseOS工程：

登录backend机器，执行create_project_BaseOS.sh，该脚本会创建BaseOS工程，并挂载everything iso拷贝rpm至指定路径；

登录source机器，执行create_project_Mainline.sh，该脚本会创建Mainline工程，并会对源码包做移动处理。

注：脚本运行时需要输入branch参数，根据实际输入，如openEuler-20.03-LTS-SP1。

2、工程project config配置:

由于script压缩包中的Mainline.prjconf、BaseOS.prjconf内容不一定适合当前版本的obs工程，需要根据实际配置适配，以openEuler-20.03-LTS-SP1说明：

访问openEuler OBS：https://build.openeuler.openatom.cn/project，查找openEuler:20.03:LTS:SP1、penEuler:20.03:LTS:SP1:selfbuild:BaseOS工程：

将openEuler:20.03:LTS:SP1的Project config内容拷贝到Mainline工程的Project Config；

将penEuler:20.03:LTS:SP1:selfbuild:BaseOS的Project Config内容拷贝到BaseOS工程的Project Config。

![img](file:///C:\Users\liuyufei\AppData\Local\Temp\ksohtml7592\wps76.jpg) 

![img](file:///C:\Users\liuyufei\AppData\Local\Temp\ksohtml7592\wps77.jpg) 

![img](file:///C:\Users\liuyufei\AppData\Local\Temp\ksohtml7592\wps78.jpg) 

注：编译失败的包，参考OBS构建FAQ排查处理。

### 4.0.2 导入jenkins任务

OBS+jenkins+gitlab自动化构建流程如下：

1. Jenkins代码同步任务定时从gitlab同步代码到OBS source节点，并自动触发工程构建。
2. Jenkins触发制作ISO任务，并推送至dailybuild服务器。

Jenkins配置文件如下：

| 配置名称                            | 用途                           |
| ----------------------------------- | ------------------------------ |
| sync_obs_repos_all                  | 代码同步并自动触发rpm构建      |
| openEuler-build-aarch64-03-make_iso | 制作ISO并推送到dailybuild repo |

 

将附件目录中的XXX导入到jenkins中，并根据自己的部署情况进行修改。

### 4.0.3 工程配置修改（for换标）

BaseOS工程的project config是基于openEuler的openEuler:20.03:LTS:SP1:selfbuild:BaseOS工程的project config配置。厂商为构建自己的iso，需要修改地方有：

1. 根据实际情况在工程的project config中自定义以下宏变量。

![img](file:///C:\Users\liuyufei\AppData\Local\Temp\ksohtml7592\wps79.jpg) 

![img](file:///C:\Users\liuyufei\AppData\Local\Temp\ksohtml7592\wps80.jpg) 

1. 去掉gcc_secure依赖：将下图所示的gcc_secure删除。

![img](file:///C:\Users\liuyufei\AppData\Local\Temp\ksohtml7592\wps81.jpg) 

### 4.0.4 创建Extras工程

Extras工程的目的是编译openEuler_chroot，为后续的iso制作做

准备。

创建Extras工程，可在前台直接新建工程，Meta复制Mainline工程Meta的repository配置。

![img](file:///C:\Users\liuyufei\AppData\Local\Temp\ksohtml7592\wps82.jpg) 

从https://gitee.com/src-openeuler/openEuler_chroot获取openEuler_chroot的代码，并在Extras工程中添加openEuler_chroot编译。

因为openEuler_chroot需要root编译，所以需要修改obs配置，让它用root编译。修改配置的步骤：

1. spec文件首行添加#needsrootforbuild。 
2. openEuler_chroot.spec中关于yum源的路径和obs server 主backend的ip需要修改。

![img](file:///C:\Users\liuyufei\AppData\Local\Temp\ksohtml7592\wps83.jpg) 

![img](file:///C:\Users\liuyufei\AppData\Local\Temp\ksohtml7592\wps84.jpg) 

3. 在OBS repo服务器的/usr/lib/obs/server/BSConfig.pm文件添加如下修改：在文件中搜索norootexceptions，找到这个变量，并按格式添加要用root编译的包。

![img](file:///C:\Users\liuyufei\AppData\Local\Temp\ksohtml7592\wps85.jpg) 

4. 重启obs repo 服务器上的 obsscheduler 服务，使配置文件生效。 

**过程中遇到的问题和解决方法**：

问题1：《制作iso》章节执行osmaker –t standard –p openEuler –v 20.03 –r LTS-SP1 -s http://obsserverip:82/Malinline/standard_x86生成的iso名为openEuler-20.03LTS-SP1-x86_64-dvd.iso，少了个’-’，导致iso安装失败。

解决方法：将img_repo.sh 脚本中的lorax --isfinal -p "${PRODUCT}" -v "${VERSION}${RELEASE}" -r "${RELEASE}" -t "${VARIANT}" --sharedir 80-openeuler --rootfs-size=4 --buildarch="$ARCH" $(cat yumrepo.file) --nomacboot --noupgrade "${BUILD}"/iso > lorax.logfile 2>&1

改成lorax --isfinal -p "${PRODUCT}" -v "${VERSION}-${RELEASE}" -r "${RELEASE}" -t "${VARIANT}" --sharedir 80-openeuler --rootfs-size=4 --buildarch="$ARCH" $(cat yumrepo.file) --nomacboot --noupgrade "${BUILD}"/iso > lorax.logfile 2>&1后，触发openEuler_chroot和oemaker编译。

### 4.0.5 OBS常用操作介绍

OBS常用操作介绍.docx

## 4.1 二次发行构建流程

### 1.1.1 换标构建流程图

![img](file:///C:\Users\liuyufei\AppData\Local\Temp\ksohtml7592\wps86.jpg) 

### 4.1.1 换标方案说明

| 方案         | 一、替换iso安装过程中的logo图片                              | 二、修改rpm信息宏和显性logo包                                | 三、修改全部宏及所有涉及logo的包                             |
| ------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 具体描述     | 不涉及源码修改、编译等流程。操作详见：openEuler换logo指导书.docx | rpm信息的宏:%vendor http://***.org%distribution ****%packager http://***.org%dist ***修改涉及logo的rpm包:openeuler-latest-releaseopeneuler-releaseopeneuler-reposopeneuler-logosopeneuler-indexhtmlanacondapython-productmdrpm包修改详见：openEuler换标工作说明.docx | 方案二基础上，增加修改宏：%_vendor ***除涉及logo的rpm包外，因为%_vendor修改导致的一些问题包也需要修改：openEuler-rpm-configglibcgccefi-rpm-macrosshimgrub2anacondapython-productmd（根据实际编译问题可能会新增要修改的包）详见：20.03 LTS 换标工作说明.docx |
| 编译工程差异 |                                                              | 1.搭建Mainline工程并依赖BaseOS工程，关闭useforbuildflag，编译全部包 | 1.搭建Modify工程并依赖BaseOS工程，打开useforbuildflag，将修改后的包放在Modify工程编译。2. 搭建Mainline工程并依赖Modify工程，关闭useforbuildflag，编译所有剩下的所有包。 |
| 工作量       | 搭建工程：1人天编译：12个小时                                | 搭建工程：1人天修改代码：0.5人天(在图片准备好的情况下)编译：12个小时 | 搭建工程：1人天修改代码：2人天(在图片准备好的情况下)编译：24个小时 |
| 风险         | 一般无编译问题，风险较小                                     | 一般无编译问题，风险较小；不影响安装启动                     | 有可能会导致其他编译问题，且需要编译某些包作为编译依赖，会导致较多重编，时间不好把控，风险较大；可能影响安装启动 |

 

说明： 方案三中10+个包为适配%_vendor修改所带来的工作量特别大，本质上是spec文件兼容性不佳所致，提需求整改中，以进一步提升厂商换标效率。

## 4.2 编译

触发所有工程重编，重编后可能会有编译错误，需要分析错误原因并解决。

## 4.3 制作iso

### 1.1.1 准备环境

在obs server上在/usr1上挂在一个大于50G的磁盘，安装openEuler_chroot包。之后chroot到/usr1/openeuler，安装oemaker及其依赖包，yum源配置为http://obsserverip:82/Malinline/standard_x86 和http://obsserverip:82/Extras/standard_x86。

### 4.3.1 制作iso

安装完后执行oemaker –t standard –p openEuler –v 20.03 –r LTS-SP1 -s “http://obsserverip:82/Malinline/standard_x86”（参数可以自行定义）。

说明：1. 在修改商标时修改了的rpm包名，需在oemaker的下载或安装列表中进行适配。

2. –p 参数与product name强相关，该值需与在《换标方案说明》环节中，anaconda和python-productmd包使用的product name保持一致。

### 4.3.2 参数说明

-t：制作iso的类型，standard是标准的dvd iso，还有debug iso，source iso等。

-p,-v,-r：用于lorax制作initrd等和制作iso，是lorax命令和mkisofs的参数，如果两者参数不匹配会导致label不匹配的问题，导致安装有问题。可以通过file *iso 和查看iso里的isolinux/isolinux.cfg配置文件的LABEL，查看两者LABEL是否匹配。

-s：制作iso的yum源，可以是多个yum源地址，用空格隔开。

详细用法参考：https://gitee.com/src-openeuler/oemaker

## 4.4 OBS构建FAQ

### 1.1.1 root构建

如果obs构建日志中有“reason：Permission denied”，或”need root”提示，则需root构建：

1. 登录backend，vim /usr/lib/obs/server/BSConfig.pm，对需要root构建的软件包进行例外配置：

![img](file:///C:\Users\liuyufei\AppData\Local\Temp\ksohtml7592\wps87.jpg) 

1. 重启backend服务，重新触发需要root构建的包：

![img](file:///C:\Users\liuyufei\AppData\Local\Temp\ksohtml7592\wps88.jpg) 

### 4.4.1 Maven源配置

1. 登录backend，vim /usr/lib/obs/server/build/settings.xml，根据实际maven源配置：

![img](file:///C:\Users\liuyufei\AppData\Local\Temp\ksohtml7592\wps89.jpg) 

1. 修改/usr/lib/obs/server/build/build文件，增加红框处配置：

![img](file:///C:\Users\liuyufei\AppData\Local\Temp\ksohtml7592\wps90.jpg) 

1. 重启backend的obs服务。

### 4.4.2 obsworker DNS配置

1. obsworker机器/etc/resolv.conf配置DNS服务器；
2. 检查backend /usr/lib/obs/server/build/init_buildsystem文件，是否有同步resolv.conf文件的动作，没有则添加：

![img](file:///C:\Users\liuyufei\AppData\Local\Temp\ksohtml7592\wps91.jpg) 

1. 重启backend服务。

### 4.4.3 rpmbuild命令行参数修改

例如obs构建时需要rpmbuild命令行添加—without参数：

1. vim /usr/lib/obs/server/build/build-recipe-spec，查看脚本进行修改：

![img](file:///C:\Users\liuyufei\AppData\Local\Temp\ksohtml7592\wps92.jpg) 

1. 重启backend服务。

### 4.4.4 obs构建环境注入环境变量

以增加https代理为例：

在obsworker机器/etc/profile中追加export https_proxy=proxyAddress:port，然后重启backned的obs服务。

### 4.4.5 obs某种架构无法构建：

1. obs Monitor界面查询是否缺少某种架构：

![img](file:///C:\Users\liuyufei\AppData\Local\Temp\ksohtml7592\wps93.jpg) 

1. 如果缺少某种架构类型，可以在backend上/srv/obs/configuration.xml配置文件中增加：

![img](file:///C:\Users\liuyufei\AppData\Local\Temp\ksohtml7592\wps94.jpg) 

### 4.4.6 编译失败提示“rerun configure with different flags”或者“recompile with -fPIC”

1. 修改提示所指软件包的spec文件，例如libpfm.spec，在%make_build CONFIG_PFMLIB_NOPYTHON=n前一行加上export CFLAGS="$RPM_OPT_FLAGS -fPIC"；
2. 重新触发libpfm编译；
3. 重新触发编译失败的包。

### 4.4.7 Nodejs下载失败：

![img](file:///C:\Users\liuyufei\AppData\Local\Temp\ksohtml7592\wps95.jpg) 

以flink包为例，如果无法访问华为云，可参考该pr修改为自己的npm源：https://gitee.com/src-openeuler/flink/commit/bc73fa45fd22a98efa0670c9e284c02bca12e72e。

### 4.4.8 测试用例失败

1. 可以选取如下方式跳过测试用例：

a. 测试用例失败的包，跳过测试用例：软件包spec文件中注释掉make check；

b. 所有包跳过测试用例：工程project Config中增加Support:  custom_build_tool-nocheck，重新构建后会安装custom_build_tool-nocheck

![img](file:///C:\Users\liuyufei\AppData\Local\Temp\ksohtml7592\wps96.jpg) 

如果未生效，仍会跑测试用例，则参考9.4，增加—nocheck参数。

2. 如果不跳过，则找开发分析测试用例失败的具体原因。

### 4.4.9 kernel编译失败

![img](file:///C:\Users\liuyufei\AppData\Local\Temp\ksohtml7592\wps97.jpg)上面截图打印找不到debugfiles.list，原因为前面debuginfo编译报错造成，

解决方案：

修改spec文件，添加如下一行可以解决

skip debuginfo packages

### 4.4.10 flink构建失败

![img](file:///C:\Users\liuyufei\AppData\Local\Temp\ksohtml7592\wps98.jpg)![img](file:///C:\Users\liuyufei\AppData\Local\Temp\ksohtml7592\wps99.jpg) 

原因为内网环境无法访问到https://mirrors.huaweicloud.com，导致node包下载失败，

该下载地址写在如上截图的patch文件中，可以根据实际地址修改。

## 4.5 OBS搭建FAQ

### 1.1.1 frontend.sh、source.sh、backend.sh执行报错，提示内核版本不支持

解决方法：脚本适配的老版本系统内核，新版本注释内核版本校验即可：

![img](file:///C:\Users\liuyufei\AppData\Local\Temp\ksohtml7592\wps100.jpg) 

### 4.5.1 frontend.sh中rake命令行执行报错:

![img](file:///C:\Users\liuyufei\AppData\Local\Temp\ksohtml7592\wps101.jpg) 

在frontend.sh  137行添加路径切换

cd /srv/www/obs/api

rake ts:stop --trace RAILS_ENV="production"

rake ts:start --trace RAILS_ENV="production"

### 4.5.2 frontend节点apache2.service因ssl证书不存在启动失败:

查看systemctl status apache2状态如下： --- 放到准备工作

![img](file:///C:\Users\liuyufei\AppData\Local\Temp\ksohtml7592\wps102.jpg) 

解决方法：

1. 需要制作ssl证书（fullchain.pem privkey.pem），并放到/srv/obs/certs/目录下：

openssl req -new -x509 -days 3650 -nodes -out fullchain.pem -keyout privkey.pem

2. 检查frontend.sh中下面命令行是否生效：

![img](file:///C:\Users\liuyufei\AppData\Local\Temp\ksohtml7592\wps103.jpg) 

### 4.5.3 source节点source_server.sh脚本执行文件拷贝出错

![img](file:///C:\Users\liuyufei\AppData\Local\Temp\ksohtml7592\wps104.jpg) 

解决方案:133-134行修改为正确路径：

cp ./service/***** /usr/lib/obs/service/

cp ./build-pkg-rpm /usr/lib/build/build-pkg-rpm

### 4.5.4 backend 节点apache2服务启动失败，obs.conf下载失败导致

![img](file:///C:\Users\liuyufei\AppData\Local\Temp\ksohtml7592\wps105.jpg) 

根据报错检查/etc/apache2/vhosts.d/obs.conf是否存在，且配置是否正确。

### 4.5.5 http://obsserver web访问失败

![img](file:///C:\Users\liuyufei\AppData\Local\Temp\ksohtml7592\wps106.jpg) 

obsserver  frontend需要修改/etc/apache2/vhosts.d 路径下obs.conf，修改为如下文件,注意其中ip地址改为自己前端机器的ip。

obs.zip

![img](file:///C:\Users\liuyufei\AppData\Local\Temp\ksohtml7592\wps107.jpg) 

### 4.5.6 obs frontend节点 sphinx 服务启动失败

![img](file:///C:\Users\liuyufei\AppData\Local\Temp\ksohtml7592\wps108.jpg) 

解决方法：chown wwwrun:www /srv/www/obs/api/tmp/binlog/production/binlog.lock没有权限：

执行chown wwwrun:www /srv/www/obs/api/tmp/binlog/production/binlog.lock

### 4.5.7 创建工程失败

![img](file:///C:\Users\liuyufei\AppData\Local\Temp\ksohtml7592\wps109.jpg) 

备注：worker虚机镜像登录 密码：root/openeuler@1234

问题定位step 1：

vim /srv/obs/log/src_server.log  报错如下：

![img](file:///C:\Users\liuyufei\AppData\Local\Temp\ksohtml7592\wps110.jpg) 

（1）unknown ”backend_002”, ”backend_003”, ”backend_004”, ”other-backend”,

（2）连接到home-backend 被拒绝

（3）localhost:5452被拒绝

逐条处理以上问题，解决方法：

（1）unknown ”backend_002”, ”backend_003”, ”backend_004”, ”other-backend”

vim /usr/lib/obs/server/BSConfig.pm

server部署了几台backend，partition相关的就只保留相关的backend,上述unknown的全部删除。  备注：BSConfig.pm该配置文件修改后都要重启该server上的obs相关服务。

![img](file:///C:\Users\liuyufei\AppData\Local\Temp\ksohtml7592\wps111.jpg) 

（2）连接到home-backend 被拒绝，启动home-backend的虚拟机。

home-backend为开启，可连通状态。

（3）localhost:5452被拒绝，注释掉5452端口。

vim /usr/lib/obs/server/BSConfig.pm

![img](file:///C:\Users\liuyufei\AppData\Local\Temp\ksohtml7592\wps112.jpg) 

问题定位step 2：

vim /srv/obs/log/src_server.log  报错如下：

![img](file:///C:\Users\liuyufei\AppData\Local\Temp\ksohtml7592\wps113.jpg) 

$ipaccess rule的问题，vim /usr/lib/obs/server/BSConfig.pm

$ipaccess 修改为自己的source backend所在网段，允许该网段内ip进行访问修改。

问题解决：

![img](file:///C:\Users\liuyufei\AppData\Local\Temp\ksohtml7592\wps114.jpg) 

再次尝试，obs创建工程成功。

### 4.5.8 osc命令报错

![img](file:///C:\Users\liuyufei\AppData\Local\Temp\ksohtml7592\wps115.jpg) 

解决：修改配置文件/root/.config/osc/oscrc：

![img](file:///C:\Users\liuyufei\AppData\Local\Temp\ksohtml7592\wps116.jpg) 

### 4.5.9 执行get_source.sh有如下报错：

![img](file:///C:\Users\liuyufei\AppData\Local\Temp\ksohtml7592\wps117.jpg) 

修改get_source.sh脚本如下：

![img](file:///C:\Users\liuyufei\AppData\Local\Temp\ksohtml7592\wps118.jpg) 

### 4.5.10 backend如下报错：

vim /srv/obs/log/dispatcher.log

![img](file:///C:\Users\liuyufei\AppData\Local\Temp\ksohtml7592\wps119.jpg) 

连接worker的时候出错，查看是否worker的防火墙没关。

systemctl status firewalld

解决：关闭worker的防火墙

systemctl stop firewalld

### 4.5.11 软件包broken

通常为拉取不到源码，先检查broken包的_service文件，查看其指向代码在源码服务器的/srv/cache/obs/tar_scm/repo/next/路径下是否存在，不存在则先在源码服务器上拉取代码，再点击obs页面包的点击Trigger services按钮同步代码到obs。

### 4.5.12 整个工程的大量包都在scheduled状态且一直没有任何在building的包

通过monitor界面检查worker状态是否正常，正常情况为正在构建或idle状态；

如果节点状态为灰色，则表示节点为down状态，需登录worker检查obs服务状态(systemctl status obsworker)，如果异常，建议先重启，不行则再检查/etc/sysconfig/obs-server配置文件，可以参照worker.sh中修改该文件配置的步骤。

### 4.5.13 如果网页上显示整个工程的大量包都在unresolvable状态

如果工程中存在要依赖的包，则检查该依赖包是否编译出满足版本要求的rpm包

如果工程中不存在要依赖的包，则检查依赖工程的二进制仓库中是否已归档满足要求的rpm包。

### 4.5.14 软件包failed，需要登录构建环境定位

systemctl status obsworker

![img](file:///C:\Users\liuyufei\AppData\Local\Temp\ksohtml7592\wps120.jpg) 

--root为软件包构建的chroot环境：

进入构建环境方式：

cd /var/cache/obs/worker/root_1（查看前台日志，是否进入该root_1）

chroot .

cd /home/abuild/rpmbuild  （软件包构建目录）

### 4.5.15 obs worker x86镜像启动失败

![img](file:///C:\Users\liuyufei\AppData\Local\Temp\ksohtml7592\wps121.jpg) 

解决方法：

使用xxx密码登录后修改/etc/fstab文件，注释掉如下行后重启(arm/x86 worker镜像登录账号密码需要联系文档负责人获取)

![img](file:///C:\Users\liuyufei\AppData\Local\Temp\ksohtml7592\wps122.jpg) 

### 4.5.16 obssource 节点 obsservice.service服务启动失败

obssource 节点 obsservice.service服务启动失败

![img](file:///C:\Users\liuyufei\AppData\Local\Temp\ksohtml7592\wps123.jpg) 

![img](file:///C:\Users\liuyufei\AppData\Local\Temp\ksohtml7592\wps124.jpg) 

解决方法：chown obsrun:obsrun  /srv/obs/run/bs_service.status